# 
# Specification for the format of variant table and definition of different variant classes
#
[Variant]
# Variant table is in tab separated text format generated by the annotation pipeline
# Mandatory fields in the table include: Chrom Position Ref Alt GeneID GeneEff
# It is possible to have multiple variant files (e.g. when we need to combined data from different studies)
# If multiple variant table are specified, they should follow the same specifications 
# listed below to link variant to genes and samples and to define variant classes
Table=DNVTable.txt

# Aliasing column names to avoid conflict with default column names
# Note that two key fields prob and weight will later be used by DenovoWEST, so if they appear in the
# original input we should rename them to avoid conflicts.
#Alias=weight:Score,prob:Probability

# Columns in the input table to be kept or removed
# Because we will extract gene-specific variants for use later, we will deal with the cases when a 
# DNV mapped to multiple genes. In such cases, we assume annotations to multiple genes are delimited by
# semicolon as in GeneID/GeneEff. Occasionally, some fields in the annotation may also include semicolon 
# but not used as a separator for gene-specific information.
# We can either keep the necessary columns to be used in defining variant class.
ColKeep=Chrom,Postion,Ref,Alt,Context,GeneID,GeneEff,REVEL
# Or just remove such columns that may cause error, only one of the column options can be used!
ColRemove=DDDOrgan

# It is also possible to specify a over-all variant level filter
Filter='(ExAC_ALL=="." | ExAC_ALL<0.001) & (gnomADexome_ALL=="." | gnomADexome_ALL<0.001)'

# A list of potentially bad variants to be removed.
# Format: VarID IID, if IID is omitted, then all variants matching VarID will be removed
Exclude=BadVariants.txt

# We will make use of the following fields in the variant table.
# Chrom,Position,Ref,Alt: the four fields will be used to uniquely specify a variant.
# GeneID will be used to look up baseline mutation rate for each gene, gene set membership, and genomic location
# Note: although most gene sets are available as gene names, we prefer to use gene IDs to keep
# consistency across all analysis pipeline. Users should prepare appropriate gene sets.
# Given all the above fields are standard fields from the annotation pipeline, 
# we don't need to specify them here except sample ID.

# SampID will be used to link to sample info for defining sex and sub-groups of samples
SampID=IID

# Variant classes
# Note: variant classes definitions will be used to construct a new column in the input variant table
# and subsequently used to determine variant weights. 
# ClassCol will specify the new column name in the input.
# Variant class should be mutually exclusive, but in case it is not, only the first one class that passed filter
# will be assigned to the variant.
ClassCol=VarClass
Class=LoF
Class_Filter='GeneEff=~"splice_(acceptor|donor)" | GeneEff=="frameshift" | GeneEff=="stop_gained"'
Class=Dmis_REVEL0.5
Class_Filter='GeneEff=="missense" & REVEL!="." & REVEL>=0.5'
Class=Bmis_REVEL0.5
Class_Filter='(GeneEff=="missense" | GeneEff=="protein_altering") & (REVEL=="." | REVEL<0.5)'
Class=Silent
Class_Filter='GeneEff=="synonymous" | GeneEff=="start_retained" | GeneEff=="stop_retained"'

# Variant removal list is different exclusion list above, we use it to remove clustered nearby variants 
# in the same individual. Because including such variant will inflate the test statistics. 
# We do not deal with variant cluster in this pipeline, but can make use of varrm output
# from dnv_burden. It should have three columns: IID VarID GeneID; we will check those IDs by regex pattern
# Make sure the same variant level filter is used in burden pipeline and this pipeline.
Remove=DNVBurden.varrm.txt

[EXOMEVAR]
# Directory that contain annotated exome SNVs in all genes (generated by enum_cdssnv.pl)
# They should contain the same annotation fields used as input file for calculating weights
DIR=GencodeV19
# Same as input, make sure prob and weight field should be renamed to something else.
#ALIAS=weight:Score
# Custom variant class, because the table only enumerate SNVs, we need to define mutation rates for indels
# from existing classes of SNVs
CUSTOM=frameshift:1.3*stop_gained
# Human genome build will be used for determining haploid chrX regions 
HGBUILD=hg19


# Variant weights
[WEIGHT]
# The lookup table for variant weights, see utils/lookup_varwt.pl for the weight file format
# Two files are provided, one include weights for all types of variants
ALLVAR=variants.txt
# The second weight table is for missense only by setting weights of other variants to 0
# This table can be optional, it missense-only weights are not provided, all missense-specific analysis will be skipped.
MISSENSE=missense.txt
# Fields used to match the relevant fields of weight table to input variant table
# For details, see documentations of utils/lookup_varwt.pl 
# Fields from input can be original name or derived field from variant class (defined by ClassCol) 
# or gene set definitions (defined by SetCol)
# Weight field will be added, and must be renamed to weight. 
FIELDS=VarClass,GeneSet,Score:CADD13,PPV:weight
# Specify the score range field in the weight table
SCORE=Score


# Sample level information, this section is similar to Sample section in dnv_burden.conf
[Sample]
# Samp size is used when sample table is not available
# It should be the number of final cleaned sample after removing those in the exclue list
# It SHOULD INCLUDE twin/sibs. Sample size used for analysis will be different if twin/sibs are present.
# It can also be group-specific sample sizes format like, All:564,Complex:200,Isolated:100
Size=4650
# Sample table, must be tab-separated
# When sample table is not provided, we will look for sample info from variant table
# In such cases, sample size in variant will typically be smaller than real sample size
# and we need to speicify the correct sample size for analysis.
Table=SampInfo.txt
# Sample ID appear in the sample table, linked to SampID in varian table
SampID=IID

# Overall sample table filter
Filter='Pheno!="Unaffected"'
# A list of bad samples to be excluded
#Exclude=BadSamps.txt
# A list of good samples to be included
#Include=GoodSamps.txt

# Twins should be counted as one sample in each group
# De novo variants shared by twins should be counted only once
#Twins=MZTwins.txt

# Sibs should be treated as distinct samples
# But de novo variants shared by sibs are from the same parental mosaic mutation
#Sibs=FullSibPairs.txt

# Sex must be M/F or Male/Female
# Sample sex information is only used to scale chrX mutation rate
Sex=Sex
# If sample with unknown sex is allowed, when some or all sample have unknown sex, 
# we will impute the total sample size for male and female. This is typically used 
# for published data when sample level information is not complete. 
AllowNoSex=Y
# If no sample table is provided or when sex information is not available 
# we can make use of this proportion to determine the sample size of males/females. 
PMale=0.809

# If we only want to analyze All samples, then no sample group needs to be defined here
# If groups are defined, DenovoWEST will be applied separately for each group defined here
Group=All
Group_Filter='IID!=""'
Group=Complex
Group_Filter='ID=="TRUE" | EP=="TRUE"'
Group=Isolated
Group_Filter='ID=="FALSE" & EP=="FALSE" & ADHD=="FALSE"'

[Gene]
# Blacklist (should contain gene IDs)
Exclude=GencodeV19GeneTable_HGNC20180722_MUC-HLA-OR_blacklist.txt

# Gene sets are not directly used by denovoWEST, but we may have gene-set dependent variant weights
# We can define gene set by any one of convention ways, and they will be used in determining
# variant wegiths. We will write gene set into a separate file and merge with input by GeneID.
SetCol=GeneSet
Set=hg19_mutrate_7mer_SPARK30K_NonAdj.txt
Set_Fields='pLI=="." | pLI>=0.5':Constrained,'pLI!="." & pLI<0.5"':NonCons


# These options in this section are the same as MutRate section in gene_mutrate.conf
[MutRate]
# Method to get local 
Method=3merDenovoNear
# Lookup table 
Lookup=MutRate_3merDenovoNear.txt
# Per-bp lookup table for mutation rate
#Rate=/path/to/tabix/db.txt.gz
# The scaling factor to transform relative rate to absolute rate
# The rate in the lookup table has been scaled to roughly match ~1.2e-8 per genome per generation 
# For 7mer rate from MrEel, the module will scale the rate internally by the recommended factor so that
# the genome-wide rate is 1.2e-8~1.3e-8
# Scale can also be a bed graph that gives region-specific scaling factor for mutation rates
# For positions that can not be found in the bedgraph, nearest position will be used.
Scale=1
# We also need a genome-reference to find the local sequence context for each variants
# Otherwise, we use on Context field from the input 
Fasta=human_g1k_v37.fasta
# Weight (0~1) defined at each base pair can be used to correct for coverage effect
#Weight=
# When weight is provided, Chunk is the size of genomic regions for weights to be kept in RAM
Chunk=100000

# Output table
# Default columns for each sample group tested, SampGroup prefix will be added to each column
# Starting with the number of variants in each class that are used in the test
# If variant class are defined, we use variant class, otherwise use GeneEff?
# Observed, Expected, pAllEnrich, pMisEnrich, pMisCluster, pMisComb, pDenovoWEST
[GeneTab]
# Extra-gene level information to appear in gene-based table
# Specify the fields to link additional gene level information
# The first specified field of external table should be linked to GeneID
GXref=GencodeV19GeneTable_HGNC20180722.txt
GXref_Fields=EnsemblID,HGNC
GXref=ExAC_r0.3.txt
GXref_Fields=GeneID,pLI


# Custom conda enviroment needed to run DenovoWEST and DenovoNear, 
# This is because my default conda enviroment use python3, these tools require python3.
# Comment out this section if python3 is already the default.
[CONDA]
INIT=conda.sh
ENV=py3k

# Note currently denovonear cannot be run on biocluster
[SGE]
h_vmem=8G
mem_free=8G

[BASH]
jobs=40
# reduce the number of parallel threads for denovonear test 
ClstTest.jobs=10


